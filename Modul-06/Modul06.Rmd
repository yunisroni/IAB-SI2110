---
title: "Modul 06 - Classification"
author: "Roni Yunis"
date: "4/18/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Pengantar
Analisis Prediktif bisa menggunakan dua metode yaitu;
1. Classification: suatu bentuk dasar dari analisis data dimana datanya diklasifikasi ke dalam kelas-kelas.
2. Regression: memprediksi nilai variabel numerik, misalnya angka pendapatan perusahaan atau angka penjualan.

Untuk mendukung kedua hal tersebut, maka diperlukan **Machine Learning (ML)**, ML adalah tentang bagaimana membuat komputer belajar dan melakukan tugas dengan lebih baik berdasarkan data historis masa lalu. Pembelajaran selalu dilakukan berdasarkan pada observasi dari data yang tersedia. Ada dua jenis ML.
1. Supervised Learning: yaitu mesin membuat model prediktif dengan bantuan sekumpulan data pelatihan (data training) atau sering disebut juga pembelajaran dengan pengawasan, karena variabel yang digunakan sudah ditentukan
2. Unsupervised Learning: yaitu model prediktif yang tidak menggunakan data pelatihan (data training), tidak ada variabel target, sehingga sering disebut dengan pembelajaran tanpa pengawasan, karena variabel yang digunakan tidak ditentukan.

Untuk menghasilkan model prediksi yang baik, sehingga dataset bisa dibagi menjadi 3 bagian, yaitu:
a.	**Training Data Partition**: Partisi data pelatihan (data training) digunakan untuk melatih model. Rincian variabel hasil sudah diketahui. Untuk masalah klasifikasi, kelas variabel hasil sudah ditentukan dan terkadang dibuat secara manual dengan campur tangan manusia.
b.	**Test Data Partitions**: Partisi data pengujian (data testing) adalah bagian dari kumpulan data yang tidak ada dalam kumpulan pelatihan. Ini digunakan untuk menilai kinerja model untuk data baru. Partisi ini terkadang disebut partisi testing. Model harus bekerja dengan baik untuk data set pelatihan dan data pengujian.
c.	**Validation Data Partition**: Partisi data validasi digunakan untuk menyempurnakan kinerja model dan mengurangi masalah overfitting. Partisi ini dapat digunakan untuk menilai beberapa model dan memilih model terbaik. Kumpulan data ini tidak digunakan untuk membangun model. Jadi, model tersebut belum pernah melihat kumpulan data ini sebelumnya. Ini membantu menyempurnakan kinerja model dan mengurangi overfitting.

**Overfitting** adalah suatu keadaan dimana data yang digunakan untuk pelatihan itu adalah yang terbaik. Sehingga apabila dilakukan tes dengan menggunakan data yang berbeda dapat mengurangi akurasi (wikipedia)

Pada pembahasan kali ini, kita akan membahas Klasifikasi, Klasifikasi adalah metode analisis data yang digunakan untuk menemukan pola dalam data. Klasifikasi memprediksi kelas kategorikal, sedangkan regresi memprediksi fungsi nilai kontinyu. Contoh penerapan model klasifikasi adalah untuk memprediksi hasil dari proses persetujuan aplikasi kartu kredit (disetujui atau ditolak) atau untuk menentukan klain asuransi. Ada banyak algoritma klasifikasi yang sudah dikembangkan dan dapat kita gunakan untuk menunjang prediksi yang akan dilakukan. Berikut algoritma klasifikasi yang bisa digunakan, diantaranya yaitu Naive Bayes, Decision Tree, K-Nearest Neighbor (KNN), Random Forest, dll. Dalam pembahasan pada Modul 07 ini, kita akan bahas bagaimana cara menggunakan Algoritma Desicion Tree dan Random Forest untuk memprediksi dan mengklasifikasi dataset *credit.csv*

# Load Packages
Untuk mendukung klasifikasi yang akan dilakukan, maka ada beberapa packages/library yang diperlukan.
```{r}
# Package untuk manipulasi data
library(dplyr)
# Package untuk visualisasi data
library (ggplot2)
# package untuk praktisi data
library(caret)
# package untuk klasifikasi
library(randomForest)
# package untuk mengukur perfomansi model klasifikasi
library(e1071)
# package untuk menguji kehandalan dari model prediksi
library(ROCit)
# package untuk decision tree
library(rpart)
# pakage untuk memodelkan pohon keputusan
library(rpart.plot)
```


# Data Preparation
Import data dan melihat struktur data
```{r}
credit <- read.csv("data/credit.csv")
glimpse(credit)
```
Melihat ringkasan dari data
```{r}
summary(credit)
```
Melihat 6 baris teratas dari data credit
```{r}
head(credit)
```
Melihat 6 baris terakhir dari data credit
```{r}
tail(credit)
```
Kalau kita lihat ada beberapa variabel yang type datanya kategorical, yaitu variabel `checking_balance`, `saving_balance`, `employment_length`, `personal_status`, `other_debtors`, `property`, `installment_plan`, `housing`, `telephone`, `foreign_worker`, `credit_history`, `purpose`, dan `job`

# EDA dan Visualisasi
Melihat data kosong atau missing value (NA's)
```{r}
colSums(is.na(credit))
```
Bisa dilihat bahwa tidak ada data kosong atau NA's

Kita lanjutkan melihat kategorikal dari beberapa variabel`
```{r}
# melihat kategori dari checking_balance
table(credit$checking_balance)
```
Bisa dilihat ada 4 kategori, yaitu <0, 1-200, >200, dan unknown

```{r}
# melihat kategori dari savings_balance
table(credit$savings_balance)
```
Bisa dilihat ada 5 kategori, <100, 101-500, 501-100, >1000, dan unknown

```{r}
# melihat kategori dari housing
table(credit$housing)
```
Ternyata housing terbanyak adalah untuk kategori own

```{r}
# melihat kategori dari property
table(credit$property)
```

```{r}
# Melihat kategori dari month_loan_duration dan purpose
table(credit$months_loan_duration, credit$purpose)
```


```{r}
# melihat kategori purpose
table(credit$purpose)
```
Bisa dilihat ada 10 kategori. Kategori yang paling banyak adalah radio/tv

```{r}
# melihat kategori dari foreign worker
table(credit$foreign_worker)
```
Ternyata katori untuk pekerja asing yang paling banyak yaitu sebanyak 963

```{r}
# melihat kategori credit_history
table(credit$credit_history)
```

Kategori credit history yang paling banyak adalah repaid.

```{r}
# melihat asosiasi antara purpose dan credit history
table(credit$purpose, credit$credit_history)

```
Ternyata bisa dilihat bahwa repaid dan untuk tujuan radio/tv adalah yang paling banyak yaitu sebanyak 167

kita akan filter, credit purpose = "radio/tv"
```{r}
radiotv <- filter(credit, purpose == "radio/tv")
head(radiotv)
```
Kita akan melihat berapa banyak pekerja asing yang mengajukan credit utk tujuan radio/tv

```{r}
radiotv %>% 
  group_by(foreign_worker) %>% 
  count() %>% 
  arrange(-n)

```
Bisa kita lihat bahwa pekerja asing dengan tujuan credit utk radio/tv ada sebanyak 275

Sekarang kita akan melihat berapa jumlah pengajuan credit dilihat dari jenis pekerjaan (job)

```{r}
radiotv %>% 
  group_by(job) %>% 
  count() %>% 
  arrange(-n) 
```
Jenis pekerjaan yang paling banyak mengajukan credit utk radio/tv adalah *skilled employee*

```{r}
radiotv %>% 
  group_by(personal_status) %>% 
  count() %>% 
  arrange(-n)
  
```
Jumlah pekerja dengan status *single male* ada sebanyak 146 orang

Kita akan melihat hubungan antara jenis pekerjaan dengan personal status

```{r}
table(radiotv$job, radiotv$personal_status)
```
Bisa dilihat bahwa jenis pekerjaan *skill employee* dengan status *single male* yang paling banyak yaitu 103 orang

```{r}
# Visualisasi yang mengajukan credit dengan tujuan radio/tv dilihat dari umur dan jenis pekerjaan
radiotv %>% 
  ggplot(aes(x=job, y=age, col=personal_status, fill=personal_status)) +
  geom_jitter() + 
  geom_boxplot() +
  labs( 
    title = "Jenis Pekerjaan dan Umur", 
    subtitle = "Credit Purpose Radio/tv", 
    caption = "by: Roni Yunis", 
    x = "Pekerjaan", 
    y = "Umur" 
  ) + 
  theme_minimal()
 

```

# Membagi Dataset
```{r}
set.seed(100) #pengambilan data secara random
#untuk data training diambil 70%, sisanya untuk data testing, berdasarkan variabel foreign_worker
index_train <- createDataPartition(credit$foreign_worker,
                                   p = 0.7,list = FALSE)

data.train <- credit[index_train,]
data.test <- credit[-index_train,]
```

```{r}
dim(data.train)
dim(data.test)
```

Setelah kita bagi, maka bisa dijelaskan bahwa untuk data training ada 701 baris data dan untuk data testing ada 299 baris data yang kita gunakan utk mendukung klasifikasikan yang akan dilakukan.

# Model Klasifikasi dengan Decision Tree
## Memodelkan klasifikasi
```{r}
modelTree <- rpart(data=data.train,
               foreign_worker~.,
               control = rpart.control(cp=0, minsplit=15))
```
opsi minsplit = 15 memgandung pengertian bahwa jika ada node yang berukuran kurang dari 15, maka algoritma dihentikan


```{r}
modelTree
```
## Visualisasi Model Klasifikasi
```{r}
# Menampikan pohon klasifikasi
rpart.plot(modelTree, extra=4,box.palette="RdBu", shadow.col="gray", nn=TRUE)

```
Dari gambarkan visualisasi diatas bisa dijelaskan bahwa keputusan terbaik untuk foreign_worker yang mengajukan credit adalah dengan durasi lama pinjaman < 11 bulan, dgn tujuan pinjaman utk membeli mobil baru dengan peluang sebasar 0,87. 

## Mengukur Kinerja Prediksi
```{r}
prediksiTree <- predict(modelTree, data.test)
head(prediksiTree, n=10)
```

```{r}
prediksi.status.t <- ifelse(prediksiTree[,2] > 0.5, "yes", "no")
#menghitung ukuran kinerja prediksi
confusionMatrix(as.factor(prediksi.status.t), as.factor(data.test$foreign_worker))
```
Berdasarkan hasil diatas bisa lihat bahwa nilai akurasi sebesar 95,6%

## Hitung Nilai Performance dari Prediksi
Kurva ini digunakan untuk menilai hasil prediksi
```{r}
ngitungROCt <- rocit(score=prediksiTree[,2],class=data.test$foreign_worker)
plot(ngitungROCt)
```
Setelah didapatkan nilai curva, maka langkah selanjutnya adalah menghitung Area Under Curve (AUC) yang nantinya dijadikan sebagai dasarkan untuk menentukan ketepatan prediksi klasifikasi yang sudah lakukan. Nilai AUC bisa dikelompokkan atas:
a. 0.90 - 1.00 = Exellence Classification
b. 0.80 - 0.90 = Good Classification
c. 0.70 - 0.80 = Fair Classification
d. 0.60 - 0.70 = Poor Classification
e. 0.50 - 0.60 = Failur

Dalam banyak kasus, nilai AUC ini juga digunakan untuk mengukur perbedaan performansi metode klasifikasi.

```{r}
# Menghitung Area Under Curve (AUC)
AUCtree <- ngitungROCt$AUC
AUCtree
```
Nilai AUC nya adalah 73,1%, artinya klasifikasi yang dihasilkan termasuk pada **fair classification**


# Model Klasifikasi dengan Random Forest
## Memodelkan klasifikasi
```{r}
set.seed(123) #menentukan nilai acak dari data
modelForest <- randomForest(data=data.train,
               as.factor(foreign_worker)~.,
               ntree=100, mtry=3)

```

```{r}
modelForest
```
Tingkat kesalahan sebesar 3,71% atau dengan akurasi sebesar 96,29%

## Mengukur kinerja prediksi
```{r}
hasilPrediksi <- predict(modelForest, data.test, type="prob")
head(hasilPrediksi, n=10)
```

## Menampilkan plot hasil prediksi
```{r} 
plot(hasilPrediksi )
```
```{r}
prediksi.status.f <- ifelse(hasilPrediksi[,2] > 0.5, "yes", "no")

#menghitung ukuran kinerja prediksi
confusionMatrix(as.factor(prediksi.status.f), as.factor(data.test$foreign_worker))
```
Berdasarkan hasil diatas bisa lihat bahwa nilai akurasi sebesar 96,3 %

## Hitung Nilai Performance dari Prediksi

```{r}
ngitungROCf <- rocit(score=hasilPrediksi[,2],class=data.test$foreign_worker)
plot(ngitungROCf)
```
```{r}
AUCf <- ngitungROCf$AUC
AUCf
```
Nilai AUC nya adalah 76,5%, artinya klasifikasi yang dihasilkan termasuk pada **fair classification**

Kalau kita bandingkan dari kedua model tersebut, kinerja dari klasifikasi dengan *Random Forest* **lebih baik sedikit** dibandingkan dengan *Decision Tree*



